{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ash RL Training (Colab/PyTorch Version)\n",
    "\n",
    "This notebook implements the Reinforcement Learning loop for Bash command generation using PyTorch and Hugging Face Transformers, compatible with Google Colab (Linux/CUDA) or local NVIDIA GPUs.\n",
    "\n",
    "Original Code: [ash-rl-mlx](https://github.com/Krabbens/ash-rl-mlx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Environment\n",
    "import os\n",
    "if os.path.exists(\"ash-rl-mlx\"):\n",
    "    %cd ash-rl-mlx\n",
    "    !git pull\n",
    "else:\n",
    "    !git clone https://github.com/Krabbens/ash-rl-mlx.git\n",
    "    %cd ash-rl-mlx\n",
    "\n",
    "!pip install -q transformers peft bitsandbytes trl accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "# Import local modules from the cloned repo\n",
    "# Ensure we are in the right directory\n",
    "if not os.path.exists(\"terminal_bench.py\"):\n",
    "    raise FileNotFoundError(\"Please run the git clone cell first!\")\n",
    "\n",
    "from terminal_bench import TerminalBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration & Helpers\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "OUTPUT_DIR = \"./adapters_pt\"\n",
    "METRICS_FILE = \"metrics_pt.jsonl\"\n",
    "NUM_ITERATIONS = 50\n",
    "\n",
    "# Reward Function (Ported from main.py)\n",
    "def check_bash_syntax(cmd):\n",
    "    if not cmd: return False\n",
    "    try:\n",
    "        res = subprocess.run([\"bash\", \"-n\"], input=cmd, text=True, capture_output=True, timeout=1)\n",
    "        return res.returncode == 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def calculate_reward(success, eval_meta, cmd, prompt):\n",
    "    if not cmd: return 0.0\n",
    "    reward = 0.0\n",
    "    \n",
    "    # 1. Base success\n",
    "    if success: reward += 2.0\n",
    "    \n",
    "    # 2. Syntax\n",
    "    if check_bash_syntax(cmd): reward += 0.3\n",
    "    \n",
    "    # 3. Execution status\n",
    "    if eval_meta.get(\"exit_code\") == 0: reward += 0.2\n",
    "    elif eval_meta.get(\"exit_code\") == 124: reward -= 0.5\n",
    "        \n",
    "    # 4. Keyword matching\n",
    "    potential_files = re.findall(r'/?app/([\\w\\.\\-]+)', prompt)\n",
    "    for f in potential_files:\n",
    "        if f in cmd: reward += 0.1\n",
    "            \n",
    "    # 5. Hallucinations/Bad patterns\n",
    "    if \"<<\" in cmd and \"jq\" in cmd: reward -= 0.5\n",
    "    if cmd.strip().endswith(\"|\"): reward -= 0.5\n",
    "    \n",
    "    # 7. Python/Non-bash penalty (Refined)\n",
    "    bad_python = [\"import os\", \"import sys\", \"import json\", \"def main(\", \"if __name__ ==\", \"class \"]\n",
    "    if any(k in cmd for k in bad_python):\n",
    "        reward -= 2.0\n",
    "    \n",
    "    # 6. Brevity penalty\n",
    "    len_penalty = max(0, (len(cmd) - 100) * 0.0001)\n",
    "    reward -= len_penalty\n",
    "    \n",
    "    return max(0.0, reward)\n",
    "\n",
    "def extract_command(response):\n",
    "    # 1. Code blocks\n",
    "    code_blocks = re.findall(r'```(?:bash|sh)?\\n(.*?)```', response, re.DOTALL)\n",
    "    if code_blocks:\n",
    "        return \"\\n\".join([b.strip() for b in code_blocks])\n",
    "    \n",
    "    # 2. Extract after thinking tags\n",
    "    if \"</thinking>\" in response:\n",
    "        after = response.split(\"</thinking>\")[-1].strip()\n",
    "        # Simple heuristic: take lines that look like commands\n",
    "        lines = [l.strip() for l in after.split('\\n') if l.strip()]\n",
    "        # Just return the whole block if unsure, specifically stripped\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    # 3. Fallback: Last line\n",
    "    lines = response.strip().split('\\n')\n",
    "    for line in reversed(lines):\n",
    "        cl = line.strip()\n",
    "        if cl and not cl.startswith(('#', 'Here', 'To', 'Step', 'Note')):\n",
    "            return cl\n",
    "    return response.strip()\n",
    "\n",
    "def clean_command(cmd):\n",
    "    if not cmd: return cmd\n",
    "    lines = cmd.split('\\n')\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        if '#' in line:\n",
    "            line = line.split('#')[0]\n",
    "        if line.strip():\n",
    "            cleaned.append(line.strip())\n",
    "    return '\\n'.join(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize Model & Tokenizer\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "\n",
    "# Load in bfloat16 for efficiency on T4/A100\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "# Apply LoRA Adapter\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Main Training Loop\n",
    "# Setup Bench\n",
    "FULL_DATASET_PATH = \"terminal_bench_full.json\"\n",
    "if not os.path.exists(FULL_DATASET_PATH):\n",
    "    print(\"Warning: Full dataset not found, using internal local tasks only.\")\n",
    "    bench = TerminalBench()\n",
    "else:\n",
    "    bench = TerminalBench(task_file=FULL_DATASET_PATH)\n",
    "\n",
    "all_tasks = bench.get_tasks()\n",
    "print(f\"Loaded {len(all_tasks)} tasks.\")\n",
    "\n",
    "data_dir = \"data_bash_pt\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(f\"\\n=== Iteration {iteration+1}/{NUM_ITERATIONS} ===\")\n",
    "    \n",
    "    # Curriculum - Strictly enforce easy tasks first\n",
    "    if iteration < 5:\n",
    "        # ONLY allow known easy categories from local tasks (basic, files, text)\n",
    "        # Exclude 'easy' because external tasks use it for hard things\n",
    "        filtered_tasks = [t for t in all_tasks if t.get(\"category\", \"\").lower() in [\"basic\", \"files\", \"text\"]]\n",
    "    elif iteration < 15:\n",
    "        filtered_tasks = [t for t in all_tasks if t.get(\"category\", \"\").lower() in [\"basic\", \"files\", \"text\", \"medium\", \"search\", \"script\"]]\n",
    "    else:\n",
    "        filtered_tasks = all_tasks\n",
    "    \n",
    "    # Fallback if filtering removes everything (shouldn't happen with local tasks merged)\n",
    "    if not filtered_tasks:\n",
    "        filtered_tasks = all_tasks\n",
    "        \n",
    "    # Sample tasks to keep iteration speed high\n",
    "    random.shuffle(filtered_tasks)\n",
    "    current_tasks = filtered_tasks[:16] # Micro-batch size\n",
    "    \n",
    "    candidates = []\n",
    "    solved_count = 0\n",
    "    train_file = os.path.join(data_dir, \"train.jsonl\")\n",
    "    open(train_file, \"w\").close() # Clear file\n",
    "    \n",
    "    # --- GENERATION PHASE ---\n",
    "    model.eval()\n",
    "    # Prepare batch\n",
    "    prompts_text = []\n",
    "    sys_prompt = \"You are a Linux terminal. CWD: /app. Plan in <thinking>. Output ONLY raw bash commands in a ```bash block. No comments.\"\n",
    "    \n",
    "    for task in current_tasks:\n",
    "        messages = [{\"role\": \"system\", \"content\": sys_prompt}, {\"role\": \"user\", \"content\": task[\"prompt\"]}]\n",
    "        text_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        prompts_text.append(text_prompt)\n",
    "        \n",
    "    # Batch generation\n",
    "    inputs = tokenizer(prompts_text, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=1024, \n",
    "            do_sample=True, \n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    decoded_responses = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    for i, response in enumerate(decoded_responses):\n",
    "        task = current_tasks[i]\n",
    "        prompt = task[\"prompt\"]\n",
    "        cmd = clean_command(extract_command(response))\n",
    "        \n",
    "        # Reconstruct messages for training data\n",
    "        messages = [{\"role\": \"system\", \"content\": sys_prompt}, {\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        # Evaluate\n",
    "        success, meta = bench.evaluate_task(task, {'command': cmd})\n",
    "        reward = calculate_reward(success, meta, cmd, prompt)\n",
    "        \n",
    "        is_solved = (reward >= 1.0)\n",
    "        status = \"\u2705\" if is_solved else \"\u274c\"\n",
    "        print(f\"  {status} [{task['id']}] {prompt[:40]}... -> {cmd[:50]}\")\n",
    "        \n",
    "        if is_solved:\n",
    "            solved_count += 1\n",
    "            # Create training sample\n",
    "            # We train on the FULL conversation including the thinking and correct code\n",
    "            full_messages = messages + [{\"role\": \"assistant\", \"content\": response}]\n",
    "            full_text = tokenizer.apply_chat_template(full_messages, tokenize=False)\n",
    "            \n",
    "            with open(train_file, \"a\") as f:\n",
    "                json.dump({\"text\": full_text}, f)\n",
    "                f.write(\"\\n\")\n",
    "            candidates.append(1)\n",
    "\n",
    "    print(f\"Solved {solved_count}/{len(current_tasks)} tasks.\")\n",
    "    \n",
    "    # --- TRAINING PHASE ---\n",
    "    if candidates:\n",
    "        print(f\"Training on {len(candidates)} samples...\")\n",
    "        model.train()\n",
    "        \n",
    "        dataset = load_dataset(\"json\", data_files=train_file, split=\"train\")\n",
    "        \n",
    "        training_args = SFTConfig(\n",
    "            output_dir=OUTPUT_DIR,\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=16,\n",
    "            gradient_accumulation_steps=4,\n",
    "            learning_rate=1e-5,\n",
    "            logging_steps=1,\n",
    "            save_strategy=\"no\",\n",
    "            report_to=\"none\",\n",
    "            dataset_text_field=\"text\",\n",
    "            max_seq_length=1024,\n",
    "            packing=False # Simple for now\n",
    "        )\n",
    "        \n",
    "        trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            train_dataset=dataset,\n",
    "            args=training_args,\n",
    "            processing_class=tokenizer,\n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        # Save adapter occasionally\n",
    "        if (iteration + 1) % 10 == 0:\n",
    "            trainer.save_model(os.path.join(OUTPUT_DIR, f\"ckpt-{iteration+1}\"))\n",
    "    else:\n",
    "        print(\"No successful samples to train on.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}